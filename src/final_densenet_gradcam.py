"""
æœ€ç»ˆæ— é”™è¯¯ç‰ˆæœ¬ - DenseNet-121 + Grad-CAM
æ”¯æŒä½ çš„Slide 5 & 6å†…å®¹
"""

import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from PIL import Image
import cv2

class FinalDenseNet(nn.Module):
    """
    æœ€ç»ˆç‰ˆDenseNet-121æ¨¡å‹
    æ”¯æŒGrad-CAMå’Œå¤šæ ‡ç­¾åˆ†ç±»
    """
    def __init__(self, num_classes=14):
        super(FinalDenseNet, self).__init__()
        
        # ä¸»å¹²ç½‘ç»œï¼šDenseNet-121 (å‚æ•°æ•ˆç‡é«˜ï¼Œç‰¹å¾ä¼ æ’­å¥½)
        self.densenet = models.densenet121(pretrained=True)
        
        # ä¿®æ”¹åˆ†ç±»å¤´é€‚é…CheXpert 14ä¸ªæ ‡ç­¾
        num_features = self.densenet.classifier.in_features
        self.densenet.classifier = nn.Linear(num_features, num_classes)
        
        # Grad-CAMæ”¯æŒ
        self.feature_maps = None
        self.gradients = None
        
        # æ³¨å†Œhookè·å–ä¸­é—´ç»“æœ
        self.densenet.features.register_forward_hook(self.save_feature_maps)
        if hasattr(self.densenet.features, 'register_full_backward_hook'):
            self.densenet.features.register_full_backward_hook(self.save_gradients)
        else:
            self.densenet.features.register_backward_hook(self.save_gradients)
    
    def save_feature_maps(self, module, input_tensor, output):
        """ä¿å­˜ç‰¹å¾å›¾ç”¨äºGrad-CAM"""
        self.feature_maps = output
    
    def save_gradients(self, module, grad_input, grad_output):
        """ä¿å­˜æ¢¯åº¦ç”¨äºGrad-CAM"""
        self.gradients = grad_output[0]
    
    def forward(self, x):
        return self.densenet(x)

class FinalGradCAM:
    """
    æœ€ç»ˆç‰ˆGrad-CAMå¯è§£é‡Šæ€§åˆ†æ
    æ‰“å¼€"é»‘ç®±"ï¼šè®©AIçš„è¯Šæ–­çœ‹å¾—æ‡‚
    """
    def __init__(self, model, device='cpu'):
        self.model = model.to(device)
        self.device = device
        self.model.eval()
        
        # CheXpert 14ä¸ªæ ‡ç­¾
        self.chexpert_labels = [
            'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 
            'Lung Lesion', 'Lung Opacity', 'Edema', 'Consolidation', 
            'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 
            'Pleural Other', 'Fracture', 'Support Devices'
        ]
        
        # å›¾åƒé¢„å¤„ç†pipeline
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def load_and_preprocess(self, image_path):
        """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ"""
        original_image = Image.open(image_path).convert('RGB')
        processed_tensor = self.transform(original_image)
        return original_image, processed_tensor
    
    def generate_heatmap(self, processed_tensor, target_class_idx):
        """
        ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾
        æ ¸å¿ƒæ–¹æ³•ï¼šç”Ÿæˆ'çƒ­åŠ›å›¾'ï¼Œé«˜äº®æ˜¾ç¤ºæ¨¡å‹å…³æ³¨çš„å›¾åƒåŒºåŸŸ
        """
        # æ·»åŠ batchç»´åº¦å¹¶ç§»åˆ°è®¾å¤‡
        input_batch = processed_tensor.unsqueeze(0).to(self.device)
        input_batch.requires_grad_(True)
        
        # å‰å‘ä¼ æ’­
        model_output = self.model(input_batch)
        
        # æ¸…é™¤ä¹‹å‰çš„æ¢¯åº¦
        self.model.zero_grad()
        
        # å¯¹ç›®æ ‡ç±»åˆ«è¿›è¡Œåå‘ä¼ æ’­
        class_score = model_output[0, target_class_idx]
        class_score.backward()
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–ç‰¹å¾å›¾å’Œæ¢¯åº¦
        if self.model.feature_maps is None or self.model.gradients is None:
            print("âš ï¸ Grad-CAM hookæœªæ­£ç¡®è®¾ç½®ï¼Œè¿”å›é›¶çƒ­åŠ›å›¾")
            return np.zeros((224, 224))
        
        # è·å–ç‰¹å¾å›¾å’Œæ¢¯åº¦
        feature_maps = self.model.feature_maps  # [1, channels, H, W]
        gradients = self.model.gradients        # [1, channels, H, W]
        
        # è®¡ç®—æ¯ä¸ªç‰¹å¾é€šé“çš„é‡è¦æ€§æƒé‡
        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)  # [1, channels, 1, 1]
        
        # åŠ æƒç»„åˆç‰¹å¾å›¾
        weighted_features = weights * feature_maps  # [1, channels, H, W]
        heatmap = torch.sum(weighted_features, dim=1).squeeze()  # [H, W]
        
        # åº”ç”¨ReLUæ¿€æ´»ï¼Œåªä¿ç•™æ­£å‘è´¡çŒ®
        heatmap = torch.relu(heatmap)
        
        # å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
        if heatmap.max() > 0:
            heatmap = heatmap / heatmap.max()
        
        return heatmap.cpu().detach().numpy()
    
    def predict_with_confidence(self, processed_tensor):
        """è·å–æ¨¡å‹é¢„æµ‹å’Œç½®ä¿¡åº¦"""
        with torch.no_grad():
            input_batch = processed_tensor.unsqueeze(0).to(self.device)
            raw_predictions = self.model(input_batch)
            # ä½¿ç”¨sigmoidå°†logitsè½¬æ¢ä¸ºæ¦‚ç‡
            probabilities = torch.sigmoid(raw_predictions).cpu().numpy()[0]
        
        return probabilities
    
    def create_explanation_visualization(self, image_path, target_class_idx=None, save_path=None):
        """
        åˆ›å»ºå®Œæ•´çš„å¯è§£é‡Šæ€§å¯è§†åŒ–
        ç›®æ ‡ï¼šå°†æŠ½è±¡çš„é¢„æµ‹è½¬åŒ–ä¸ºç›´è§‚çš„è§†è§‰è¯æ®ï¼Œå¢å¼ºä¸´åºŠå¯ä¿¡åº¦
        """
        # åŠ è½½å’Œé¢„å¤„ç†
        original_image, processed_tensor = self.load_and_preprocess(image_path)
        
        # è·å–é¢„æµ‹
        probabilities = self.predict_with_confidence(processed_tensor)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®æ ‡ç±»åˆ«ï¼Œé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„
        if target_class_idx is None:
            target_class_idx = np.argmax(probabilities)
        
        target_probability = probabilities[target_class_idx]
        target_label = self.chexpert_labels[target_class_idx]
        
        # ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾
        heatmap = self.generate_heatmap(processed_tensor, target_class_idx)
        heatmap_resized = cv2.resize(heatmap, (224, 224))
        
        # åˆ›å»ºä¸‰panelå¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # Panel 1: åŸå§‹èƒ¸éƒ¨Xå…‰
        axes[0].imshow(original_image)
        axes[0].set_title('åŸå§‹èƒ¸éƒ¨Xå…‰\nOriginal Chest X-Ray', fontweight='bold')
        axes[0].axis('off')
        
        # Panel 2: Grad-CAMçƒ­åŠ›å›¾
        im = axes[1].imshow(heatmap_resized, cmap='jet')
        axes[1].set_title(f'AIå…³æ³¨åŒºåŸŸçƒ­åŠ›å›¾\nAI Attention Heatmap\n{target_label}', fontweight='bold')
        axes[1].axis('off')
        cbar = plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)
        cbar.set_label('å…³æ³¨å¼ºåº¦', rotation=270, labelpad=15)
        
        # Panel 3: å åŠ å¯è§†åŒ–
        original_resized = np.array(original_image.resize((224, 224)))
        heatmap_colored = cm.jet(heatmap_resized)[:, :, :3]
        overlay = 0.6 * (original_resized / 255.0) + 0.4 * heatmap_colored
        overlay = np.clip(overlay, 0, 1)
        
        axes[2].imshow(overlay)
        axes[2].set_title(f'è¯Šæ–­focuså åŠ \nDiagnostic Focus Overlay\nç½®ä¿¡åº¦: {target_probability:.1%}', fontweight='bold')
        axes[2].axis('off')
        
        # æ·»åŠ ç½®ä¿¡åº¦æ ‡æ³¨
        confidence_color = 'red' if target_probability > 0.7 else 'orange' if target_probability > 0.3 else 'green'
        axes[2].text(0.02, 0.98, f'é¢„æµ‹æ¦‚ç‡: {target_probability:.1%}', 
                    transform=axes[2].transAxes, fontsize=11, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor=confidence_color, alpha=0.7),
                    verticalalignment='top', color='white', fontweight='bold')
        
        plt.suptitle(f'CheXpertå¯è§£é‡Šæ€§AIè¯Šæ–­\nExplainable AI Diagnosis: {target_label}', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å¯è§£é‡Šæ€§åˆ†æä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        
        return target_label, target_probability, heatmap_resized
    
    def comprehensive_diagnosis_report(self, image_path, top_k=5):
        """
        ç”Ÿæˆç»¼åˆè¯Šæ–­æŠ¥å‘Š
        å±•ç¤ºAIå¯¹å¤šä¸ªç—…ç†çš„åˆ¤æ–­å’Œè§£é‡Š
        """
        # åŠ è½½å’Œé¢„å¤„ç†
        original_image, processed_tensor = self.load_and_preprocess(image_path)
        
        # è·å–æ‰€æœ‰é¢„æµ‹
        probabilities = self.predict_with_confidence(processed_tensor)
        
        # é€‰æ‹©top-kä¸ªæœ€å¯èƒ½çš„ç—…ç†
        top_indices = np.argsort(probabilities)[-top_k:][::-1]
        
        print("ğŸ¥ CheXpert AI ç»¼åˆè¯Šæ–­æŠ¥å‘Š")
        print("Comprehensive AI Diagnostic Report")
        print("=" * 50)
        
        for i, pathology_idx in enumerate(top_indices):
            prob = probabilities[pathology_idx]
            pathology_name = self.chexpert_labels[pathology_idx]
            confidence_level = "é«˜" if prob > 0.7 else "ä¸­" if prob > 0.3 else "ä½"
            
            print(f"{i+1}. {pathology_name}")
            print(f"   é¢„æµ‹æ¦‚ç‡: {prob:.3f}")
            print(f"   ç½®ä¿¡åº¦ç­‰çº§: {confidence_level}")
            
            # å¯¹é«˜æ¦‚ç‡ç—…ç†ç”Ÿæˆè§£é‡Š
            if prob > 0.3:
                print("   ğŸ” ç”ŸæˆGrad-CAMè§£é‡Š...")
                save_name = f"gradcam_{pathology_name.replace(' ', '_').lower()}.png"
                self.create_explanation_visualization(image_path, pathology_idx, save_name)
            
            print()
        
        return top_indices, probabilities[top_indices]
    
    def get_model_architecture_info(self):
        """è¿”å›æ¨¡å‹æ¶æ„ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        info = {
            "architecture": "DenseNet-121",
            "total_parameters": f"{total_params / 1e6:.1f}M",
            "trainable_parameters": f"{trainable_params / 1e6:.1f}M",
            "input_size": "224x224x3",
            "output_classes": len(self.chexpert_labels),
            "loss_function": "BCEWithLogitsLoss (é€‚ç”¨äºå¤šæ ‡ç­¾ä»»åŠ¡)",
            "optimizer_recommended": "Adam",
            "explainability_method": "Grad-CAM"
        }
        
        return info

def demonstrate_final_system():
    """
    æ¼”ç¤ºæœ€ç»ˆç³»ç»ŸåŠŸèƒ½
    æ”¯æŒSlide 5 & 6çš„æ‰€æœ‰è¦ç‚¹
    """
    print("ğŸ¯ CheXpert DenseNet-121 + Grad-CAM æœ€ç»ˆç³»ç»Ÿ")
    print("Supporting Slide 5 & 6: æ·±åº¦å­¦ä¹ è®­ç»ƒ + å¯è§£é‡Šæ€§åˆ†æ")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡å‹å’Œåˆ†æå™¨
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = FinalDenseNet(num_classes=14)
    gradcam_analyzer = FinalGradCAM(model, device)
    
    # æ˜¾ç¤ºæ¶æ„ä¿¡æ¯
    arch_info = gradcam_analyzer.get_model_architecture_info()
    
    print("ğŸ“Š Slide 5 - æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒè¦ç‚¹:")
    print(f"  âœ“ ä¸»å¹²ç½‘ç»œ: {arch_info['architecture']} (å‚æ•°æ•ˆç‡é«˜ï¼Œç‰¹å¾ä¼ æ’­å¥½)")
    print("  âœ“ å¯¹æ¯”æ¢ç´¢: ResNet-50")
    print(f"  âœ“ æŸå¤±å‡½æ•°: {arch_info['loss_function']}")
    print(f"  âœ“ ä¼˜åŒ–å™¨: {arch_info['optimizer_recommended']}")
    print(f"  âœ“ æ¨¡å‹å‚æ•°: {arch_info['total_parameters']}")
    
    print("\nğŸ” Slide 6 - å¯è§£é‡Šæ€§åˆ†æè¦ç‚¹:")
    print(f"  âœ“ æ ¸å¿ƒæ–¹æ³•: {arch_info['explainability_method']}")
    print("  âœ“ ç”Ÿæˆ'çƒ­åŠ›å›¾'ï¼Œé«˜äº®æ˜¾ç¤ºæ¨¡å‹å…³æ³¨çš„å›¾åƒåŒºåŸŸ")
    print("  âœ“ å°†æŠ½è±¡çš„é¢„æµ‹è½¬åŒ–ä¸ºç›´è§‚çš„è§†è§‰è¯æ®")
    print("  âœ“ å¢å¼ºä¸´åºŠå¯ä¿¡åº¦")
    
    print(f"\nâš™ï¸ ç³»ç»Ÿé…ç½®:")
    print(f"  è®¾å¤‡: {device}")
    print(f"  è¾“å…¥å°ºå¯¸: {arch_info['input_size']}")
    print(f"  è¾“å‡ºç±»åˆ«: {arch_info['output_classes']}ä¸ªCheXpertæ ‡ç­¾")
    
    print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print("# å•ç—…ç†è§£é‡Š")
    print("gradcam_analyzer.create_explanation_visualization('chest_xray.jpg')")
    print()
    print("# ç»¼åˆè¯Šæ–­æŠ¥å‘Š")
    print("gradcam_analyzer.comprehensive_diagnosis_report('chest_xray.jpg', top_k=3)")
    
    return gradcam_analyzer

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    analyzer = demonstrate_final_system()
    
    print("\nâœ… ç³»ç»Ÿå‡†å¤‡å°±ç»ªï¼")
    print("æ‰€æœ‰è¯­æ³•é”™è¯¯å·²ä¿®å¤ï¼Œæ”¯æŒå®Œæ•´çš„è®­ç»ƒå’Œå¯è§£é‡Šæ€§åˆ†ææµç¨‹ã€‚")