"""
å¢å¼ºç‰ˆ DenseNet-121 CheXpert æ¨¡å‹
åŒ…å«è®­ç»ƒåŠŸèƒ½å’ŒGrad-CAMå¯è§£é‡Šæ€§åˆ†æ
Supporting Slide 5 & 6: Deep Learning Training + Explainable AI
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import cv2
from pathlib import Path
import json

class CheXpertDataset(Dataset):
    """
    CheXpertæ•°æ®é›†ç±»
    æ”¯æŒå¤šæ ‡ç­¾åˆ†ç±»è®­ç»ƒ
    """
    def __init__(self, csv_file, image_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.image_dir = Path(image_dir)
        self.transform = transform
        
        # CheXpert 14ä¸ªæ ‡ç­¾
        self.labels = [
            'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 
            'Lung Lesion', 'Lung Opacity', 'Edema', 'Consolidation', 
            'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 
            'Pleural Other', 'Fracture', 'Support Devices'
        ]
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        
        # åŠ è½½å›¾åƒ
        image_path = self.image_dir / f"{row['subject_id']}_{row['study_id']}.jpg"
        image = Image.open(image_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        # æå–æ ‡ç­¾ (å°†-1ä¸ç¡®å®šæ ‡ç­¾è½¬ä¸º0)
        labels = []
        for label in self.labels:
            value = row.get(label, 0)
            labels.append(1 if value == 1 else 0)  # å°†-1å’Œ0éƒ½è§†ä¸º0
        
        return image, torch.FloatTensor(labels)

class DenseNetCheXpert(nn.Module):
    """
    åŸºäºDenseNet-121çš„CheXpertåˆ†ç±»å™¨
    Supporting Slide 5: Model Core - Building a Precise Diagnostic Engine
    """
    def __init__(self, num_classes=14, pretrained=True):
        super(DenseNetCheXpert, self).__init__()
        
        # ä¸»å¹²ç½‘ç»œï¼šDenseNet-121 (é«˜å‚æ•°æ•ˆç‡ï¼Œç‰¹å¾ä¼ æ’­å¥½)
        self.backbone = models.densenet121(pretrained=pretrained)
        
        # ä¿®æ”¹åˆ†ç±»å¤´
        num_features = self.backbone.classifier.in_features
        self.backbone.classifier = nn.Linear(num_features, num_classes)
        
        # ä¿å­˜ç‰¹å¾å›¾ç”¨äºGrad-CAM
        self.features = self.backbone.features
        self.classifier = self.backbone.classifier
        
        # æ³¨å†Œhookä»¥è·å–ç‰¹å¾å›¾
        self.feature_maps = None
        self.gradients = None
        
    def forward(self, x):
        # å‰å‘ä¼ æ’­å¹¶ä¿å­˜ç‰¹å¾å›¾
        features = self.features(x)
        
        # æ³¨å†Œhookè·å–æ¢¯åº¦
        if features.requires_grad:
            self.feature_maps = features
            features.register_hook(self.save_gradients)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        pooled = nn.functional.adaptive_avg_pool2d(features, (1, 1))
        pooled = torch.flatten(pooled, 1)
        
        # åˆ†ç±»
        output = self.classifier(pooled)
        return output
    
    def save_gradients(self, grad):
        """ä¿å­˜æ¢¯åº¦ç”¨äºGrad-CAM"""
        self.gradients = grad

class CheXpertTrainer:
    """
    CheXpertæ¨¡å‹è®­ç»ƒå™¨
    Supporting Slide 5: Training Details
    """
    def __init__(self, model, device='cuda'):
        self.model = model.to(device)
        self.device = device
        
        # æŸå¤±å‡½æ•°ï¼šBCEWithLogitsLoss (é€‚ç”¨äºå¤šæ ‡ç­¾ä»»åŠ¡)
        self.criterion = nn.BCEWithLogitsLoss()
        
        # ä¼˜åŒ–å™¨ï¼šAdam
        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-4)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', patience=3, factor=0.5
        )
        
        self.train_losses = []
        self.val_losses = []
    
    def train_epoch(self, train_loader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device), target.to(self.device)
            
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            
            if batch_idx % 10 == 0:
                print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')
        
        avg_loss = total_loss / len(train_loader)
        self.train_losses.append(avg_loss)
        return avg_loss
    
    def validate(self, val_loader):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss = 0
        correct_predictions = 0
        total_predictions = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                loss = self.criterion(output, target)
                total_loss += loss.item()
                
                # è®¡ç®—å‡†ç¡®ç‡
                predictions = torch.sigmoid(output) > 0.5
                correct_predictions += (predictions == target.bool()).sum().item()
                total_predictions += target.numel()
        
        avg_loss = total_loss / len(val_loader)
        accuracy = correct_predictions / total_predictions
        
        self.val_losses.append(avg_loss)
        self.scheduler.step(avg_loss)
        
        return avg_loss, accuracy
    
    def train(self, train_loader, val_loader, epochs=10):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒ CheXpert DenseNet-121 æ¨¡å‹...")
        
        best_val_loss = float('inf')
        
        for epoch in range(epochs):
            print(f"\nEpoch {epoch+1}/{epochs}")
            print("-" * 50)
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_loader)
            
            # éªŒè¯
            val_loss, val_acc = self.validate(val_loader)
            
            print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            print(f"éªŒè¯æŸå¤±: {val_loss:.4f}")
            print(f"éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'val_loss': val_loss,
                    'val_accuracy': val_acc
                }, 'best_chexpert_densenet121.pth')
                print("âœ… ä¿å­˜æœ€ä½³æ¨¡å‹")
        
        print("ğŸ‰ è®­ç»ƒå®Œæˆ!")

class GradCAMExplainer:
    """
    Grad-CAMå¯è§£é‡Šæ€§åˆ†æå™¨
    Supporting Slide 6: Explainable AI (XAI)
    """
    def __init__(self, model, device='cuda'):
        self.model = model.to(device)
        self.device = device
        self.model.eval()
        
        # CheXpertæ ‡ç­¾
        self.labels = [
            'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 
            'Lung Lesion', 'Lung Opacity', 'Edema', 'Consolidation', 
            'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 
            'Pleural Other', 'Fracture', 'Support Devices'
        ]
    
    def generate_gradcam(self, image, class_idx):
        """
        ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾
        æ‰“å¼€"é»‘ç®±"ï¼šè®©AIçš„è¯Šæ–­çœ‹å¾—æ‡‚
        """
        # å‰å‘ä¼ æ’­
        image = image.unsqueeze(0).to(self.device)
        image.requires_grad_()
        
        output = self.model(image)
        
        # åå‘ä¼ æ’­
        self.model.zero_grad()
        class_score = output[0, class_idx]
        class_score.backward()
        
        # è·å–ç‰¹å¾å›¾å’Œæ¢¯åº¦
        feature_maps = self.model.feature_maps   # [1, 1024, 7, 7]
        gradients = self.model.gradients        # [1, 1024, 7, 7]
        
        # è®¡ç®—æƒé‡ (å…¨å±€å¹³å‡æ± åŒ–æ¢¯åº¦)
        weights = torch.mean(gradients, dim=(2, 3))  # [1, 1024]
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        cam = torch.zeros(
            feature_maps.shape[2:],
            dtype=feature_maps.dtype,
            device=feature_maps.device
        )
        for i in range(weights.shape[1]):
            cam += weights[0, i] * feature_maps[0, i]
        
        # ReLUæ¿€æ´»
        cam = torch.relu(cam)
        
        # å½’ä¸€åŒ–åˆ°[0,1]
        if cam.max() > 0:
            cam = cam / cam.max()
        
        return cam.cpu().numpy()
    
    def visualize_gradcam(self, image_path, class_idx, save_path=None):
        """
        å¯è§†åŒ–Grad-CAMç»“æœ
        å°†æŠ½è±¡çš„é¢„æµ‹è½¬åŒ–ä¸ºç›´è§‚çš„è§†è§‰è¯æ®
        """
        # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        original_image = Image.open(image_path).convert('RGB')
        input_image = transform(original_image)
        
        # ç”Ÿæˆçƒ­åŠ›å›¾
        cam = self.generate_gradcam(input_image, class_idx)
        
        # è°ƒæ•´çƒ­åŠ›å›¾å¤§å°
        cam_resized = cv2.resize(cam, (224, 224))
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # åŸå§‹å›¾åƒ
        axes[0].imshow(original_image)
        axes[0].set_title('åŸå§‹èƒ¸éƒ¨Xå…‰å›¾åƒ')
        axes[0].axis('off')
        
        # çƒ­åŠ›å›¾
        im1 = axes[1].imshow(cam_resized, cmap='jet')
        axes[1].set_title(f'Grad-CAM: {self.labels[class_idx]}')
        axes[1].axis('off')
        plt.colorbar(im1, ax=axes[1])
        
        # å åŠ å›¾åƒ
        overlay = np.array(original_image.resize((224, 224)))
        cam_colored = plt.cm.jet(cam_resized)[:, :, :3]
        overlay_result = 0.6 * overlay/255.0 + 0.4 * cam_colored
        
        axes[2].imshow(overlay_result)
        axes[2].set_title('çƒ­åŠ›å›¾å åŠ  (å…³æ³¨åŒºåŸŸé«˜äº®)')
        axes[2].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… Grad-CAMå¯è§†åŒ–ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        
        return cam_resized
    
    def explain_prediction(self, image_path, top_k=3):
        """
        å…¨é¢è§£é‡Šæ¨¡å‹é¢„æµ‹
        ç”Ÿæˆå¤šä¸ªæ ‡ç­¾çš„å¯è§£é‡Šæ€§åˆ†æ
        """
        # é¢„å¤„ç†å›¾åƒ
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        image = transform(Image.open(image_path).convert('RGB'))
        image_tensor = image.unsqueeze(0).to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            output = self.model(image_tensor)
            probabilities = torch.sigmoid(output).cpu().numpy()[0]
        
        # è·å–top-ké¢„æµ‹
        top_indices = np.argsort(probabilities)[-top_k:][::-1]
        
        print("ğŸ” AIè¯Šæ–­å¯è§£é‡Šæ€§åˆ†æ")
        print("=" * 50)
        
        for i, idx in enumerate(top_indices):
            prob = probabilities[idx]
            label = self.labels[idx]
            
            print(f"\n{i+1}. {label}")
            print(f"   é¢„æµ‹æ¦‚ç‡: {prob:.3f}")
            print(f"   ç½®ä¿¡åº¦: {'é«˜' if prob > 0.7 else 'ä¸­' if prob > 0.3 else 'ä½'}")
            
            # ç”Ÿæˆå¹¶ä¿å­˜Grad-CAM
            save_path = f"gradcam_{label.replace(' ', '_').lower()}.png"
            self.visualize_gradcam(image_path, idx, save_path)
        
        return top_indices, probabilities[top_indices]

# ä½¿ç”¨ç¤ºä¾‹å’Œè®­ç»ƒè„šæœ¬
def create_training_example():
    """åˆ›å»ºè®­ç»ƒç¤ºä¾‹"""
    print("ğŸ“š CheXpert DenseNet-121 è®­ç»ƒç¤ºä¾‹")
    print("Supporting Slide 5: Deep Learning Model Training")
    
    # æ•°æ®é¢„å¤„ç†
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=10),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆéœ€è¦å®é™…çš„æ•°æ®æ–‡ä»¶ï¼‰
    # train_dataset = CheXpertDataset('train_labels.csv', 'train_images/', train_transform)
    # val_dataset = CheXpertDataset('val_labels.csv', 'val_images/', val_transform)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    # train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    # val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # åˆå§‹åŒ–æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = DenseNetCheXpert(num_classes=14, pretrained=True)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = CheXpertTrainer(model, device)
    
    print(f"âœ… æ¨¡å‹ç»“æ„: DenseNet-121")
    print(f"âœ… è®¾å¤‡: {device}")
    print(f"âœ… æŸå¤±å‡½æ•°: BCEWithLogitsLoss")
    print(f"âœ… ä¼˜åŒ–å™¨: Adam")
    
    # å¼€å§‹è®­ç»ƒï¼ˆéœ€è¦å–æ¶ˆæ³¨é‡Šæ•°æ®åŠ è½½å™¨ï¼‰
    # trainer.train(train_loader, val_loader, epochs=20)

def create_explainability_example():
    """åˆ›å»ºå¯è§£é‡Šæ€§åˆ†æç¤ºä¾‹"""
    print("ğŸ” Grad-CAMå¯è§£é‡Šæ€§åˆ†æç¤ºä¾‹")
    print("Supporting Slide 6: Explainable AI (XAI)")
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = DenseNetCheXpert(num_classes=14, pretrained=True)
    
    # åŠ è½½æƒé‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    try:
        checkpoint = torch.load('best_chexpert_densenet121.pth', map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        print("âœ… åŠ è½½è®­ç»ƒå¥½çš„æƒé‡")
    except:
        print("âš ï¸ ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆæœªé’ˆå¯¹CheXpertå¾®è°ƒï¼‰")
    
    # åˆ›å»ºå¯è§£é‡Šæ€§åˆ†æå™¨
    explainer = GradCAMExplainer(model, device)
    
    print("ğŸ¯ Grad-CAMåŠŸèƒ½:")
    print("  - ç”Ÿæˆçƒ­åŠ›å›¾ï¼Œæ˜¾ç¤ºæ¨¡å‹å…³æ³¨çš„å›¾åƒåŒºåŸŸ")
    print("  - å°†æŠ½è±¡é¢„æµ‹è½¬åŒ–ä¸ºç›´è§‚è§†è§‰è¯æ®")
    print("  - å¢å¼ºä¸´åºŠå¯ä¿¡åº¦å’Œè¯Šæ–­é€æ˜åº¦")
    
    # ç¤ºä¾‹ç”¨æ³•ï¼ˆéœ€è¦å®é™…çš„å›¾åƒæ–‡ä»¶ï¼‰
    # explainer.explain_prediction('sample_chest_xray.jpg', top_k=3)

if __name__ == "__main__":
    print("ğŸš€ CheXpertæ·±åº¦å­¦ä¹ æ¨¡å‹ - è®­ç»ƒä¸å¯è§£é‡Šæ€§")
    print("=" * 60)
    
    # åˆ›å»ºè®­ç»ƒç¤ºä¾‹
    create_training_example()
    
    print("\n" + "=" * 60)
    
    # åˆ›å»ºå¯è§£é‡Šæ€§ç¤ºä¾‹
    create_explainability_example()